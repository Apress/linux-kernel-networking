chapter 4
----------

struct iphdr {
	#if defined(__LITTLE_ENDIAN_BITFIELD)
		_u8 ihl:4,
		version:4;
	#elif defined (__BIG_ENDIAN_BITFIELD)
		_u8 version:4,
		ihl:4;
	#else
	#error "Please fix <asm/byteorder.h>"
	#endif
	_u8 tos;
	_be16 tot_len;
	_be16 id;
	_be16 frag_off;
	_u8 ttl;
	_u8 protocol;
	_sum16 check;
	_be32 saddr;
	_be32 daddr;
	/*The options start here. */
};
(include/uapi/linux/ip.h)

static struct packet _type ip_packet_type __read_mostly = {
	.type = cpu_to_be16(ETH_P_IP),
	.func = ip_rcv,
};

static int __init inet_init(void)
{
	...
	dev_add_pack(&ip_packet_type);
	...
}
(net/ipv4/af_inet.c)

int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt, struct net_device
	   *orig_dev)
{
	if (iph->ihl < 5 || iph->version != 4)
		goto inhdr_error;
	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
		goto inhdr_error;
	return NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING, skb, dev, NULL,
			ip_rcv_finish);
}

static int ip_rcv_finish(struct sk_buff *skb)
{
	const struct iphdr *iph = ip_hdr(skb);
	struct rtable *rt;
	
	...
	if (!skb_dst(skb)) {
		int err = ip_route_input_noref(skb, iph->daddr, iph->saddr,
						iph->tos, skb->dev);
		if (unlikely(err)) {
			if (err == -EXDEV)
			NET_INC_STATS_BH(dev_net(skb->dev),
				LINUX_MIB_IPRPFILTER);
			goto drop;
		}
	}
	if (iph->ihl > 5 && ip_rcv_options(skb))
		goto drop;
	rt = skb_rtable(skb);
	if (rt->rt_type == RTN_MULTICAST) {
		IP_UPD_PO_STATS_BH(dev_net(rt->dst.dev), IPSTATS_MIB_INMCAST,
			skb->len);
	} else if (rt->rt_type == RTN_BROADCAST)
	IP_UPD_PO_STATS_BH(dev_net(rt->dst.dev), IPSTATS_MIB_INBCAST,
		skb->len);
	return dst_input(skb);
	

int ip_route_input_noref(struct sk_buff *skb, __be32 daddr, __be32 saddr,
		u8 tos, struct net_device *dev)
{
	int res;
	rcu_read_lock();
	. . .
	if (ipv4_is_multicast(daddr)) {
		struct in_device *in_dev = __in_dev_get_rcu(dev);
		if (in_dev) {
			int our = ip_check_mc_rcu(in_dev, daddr, saddr,
				ip_hdr(skb)->protocol);
			if (our
#ifdef CONFIG_IP_MROUTE
	||
			   (!ipv4_is_local_multicast(daddr) &&
			   	   IN_DEV_MFORWARD(in_dev))
#endif
		) {
			int res = ip_route_input_mc(skb, daddr, saddr,
							tos, dev, our);
			rcu_read_unlock();
			return res;
		  }
		}
	. . .
	}
. . .	


static int ip_route_input_mc(struct sk_buff *skb, __be32 daddr, __be32 saddr,
				u8 tos, struct net_device *dev, int our)
{
	struct rtable *rth;
	struct in_device *in_dev = __in_dev_get_rcu(dev);
	. . .
	if (our) {
		rth->dst.input= ip_local_deliver;
		rth->rt_flags |= RTCF_LOCAL;
	}
#ifdef CONFIG_IP_MROUTE
	if (!ipv4_is_local_multicast(daddr) && IN_DEV_MFORWARD(in_dev))
		rth->dst.input = ip_mr_input;
#endif
	. . .

static void ipmr_queue_xmit(struct net *net, struct mr_table *mrt,
			    struct sk_buff *skb, struct mfc_cache *c, int vifi)
{
	. . .
	ip_decrease_ttl(ip_hdr(skb));
	...
	NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, skb, skb->dev, dev,
		ipmr_forward_finish);
	return;
}

static inline int ipmr_forward_finish(struct sk_buff *skb)
{
	struct ip_options *opt = &(IPCB(skb)->opt);
	IP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTFORWDATAGRAMS);
	IP_ADD_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTOCTETS, skb->len);
	if (unlikely(opt->optlen))
		ip_forward_options(skb);
	return dst_output(skb);
}

struct ip_options {
	_be32 faddr;
	_be32 nexthop;
	unsigned char optlen;
	unsigned char srr;
	unsigned char rr;
	unsigned char ts;
	unsigned char is_strictroute:1,
	srr_is_hit:1,
	is_changed:1,
	rr_needaddr:1,
	ts_needtime:1,
	ts_needaddr:1;
	unsigned char router_alert;
	unsigned char cipso;
	unsigned char __pad2;
	unsigned char __data[0];
};
(include/net/inet_sock.h)

static inline bool ip_rcv_options(struct sk_buff *skb)
{
	struct ip_options *opt;
	const struct iphdr *iph;
	struct net_device *dev = skb->dev;
	. . .
	
	iph = ip_hdr(skb);

	opt = &(IPCB(skb)->opt);

	opt->optlen = iph->ihl*4 - sizeof(struct iphdr);

	if (ip_options_compile(dev_net(dev), opt, skb)) {
		IP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_INHDRERRORS);
		goto drop;
	}
	
struct inet_skb_parm {
	struct ip_options opt; /* Compiled IP options */
	unsigned char flags;
	u16 frag_max_size;
};
(include/net/ip.h)

int ip_options_compile(struct net *net, struct ip_options *opt, struct sk_buff *skb)
{
	...
	unsigned char *pp_ptr = NULL;
	struct rtable *rt = NULL;
	unsigned char *optptr;
	unsigned char *iph;
	int optlen, l
	
	if (skb != NULL) {
		rt = skb_rtable(skb);
		optptr = (unsigned char *)&(ip_hdr(skb)[1]);
	} else
		optptr = opt->__data;
	
	iph = optptr - sizeof(struct iphdr);
	
	for (l = opt->optlen; l > 0; ) {
		switch (*optptr) {
		case IPOPT_END:
			for (optptr++, l--; l>0; optptr++, l--) {
				if (*optptr != IPOPT_END) {
					*optptr = IPOPT_END;
					opt->is_changed = 1;
				}
			}
			goto eol;
		case IPOPT_NOOP:
			l--;
			optptr++;
			continue;
		}
		optlen = optptr[1];
		if (optlen<2 || optlen>l) {
			pp_ptr = optptr;
			goto error;
		}
		switch (*optptr) {
		case IPOPT_SSRR:
		case IPOPT_LSRR:
			...
		case IPOPT_RR:	
			if (optlen < 3) {
				pp_ptr = optptr + 1;
				goto error;
			}
			if (optptr[2] < 4) {
				pp_ptr = optptr + 2;
				goto error;
			}
			if (optptr[2] <= optlen) {
				if (optptr[2]+3 > optlen) {
					pp_ptr = optptr + 2;
					goto error;
				}
				if (rt) {
					spec_dst_fill(&spec_dst, skb);	
					memcpy(&optptr[optptr[2]-1], &spec_dst, 4);
					opt->is_changed = 1;
				}
				optptr[2] += 4;
				opt->rr_needaddr = 1;
			}
			opt->rr = optptr - iph;
			break;
		case IPOPT_TIMESTAMP:
			...
			if (optlen < 4) {
				pp_ptr = optptr + 1;
				goto error;
			}
			if (optptr[2] < 5) {
				pp_ptr = optptr + 2;
				goto error;
			}
			if (optptr[2] <= optlen) {
				unsigned char *timeptr = NULL;
				if (optptr[2]+3 > optptr[1]) {
					pp_ptr = optptr + 2;
					goto error;
				}
				switch (optptr[3]&0xF) {
					case IPOPT_TS_TSONLY:
						if (skb)
							timeptr = &optptr[optptr[2]-1];
						opt->ts_needtime = 1;	
						optptr[2] += 4;
						break;
					case IPOPT_TS_TSANDADDR:
						if (optptr[2]+7 > optptr[1]) {
							pp_ptr = optptr + 2;
							goto error;
						}
						if (rt) {
							spec_dst_fill(&spec_dst, skb);
							memcpy(&optptr[optptr[2]-1],
								&spec_dst, 4);
							timeptr = &optptr[optptr[2]+3];
						}
						opt->ts_needaddr = 1;
						opt->ts_needtime = 1;						
						optptr[2] += 8;
						break;
					case IPOPT_TS_PRESPEC:
						if (optptr[2]+7 > optptr[1]) {
							pp_ptr = optptr + 2;
							goto error;
						}
						{
						_be32 addr;
						memcpy(&addr, &optptr[optptr[2]-1], 4);
						if (inet_addr_type(net,addr) == RTN_UNICAST)
							break;
						if (skb)
							timeptr = &optptr[optptr[2]+3];
						}
						opt->ts_needtime = 1;	
						optptr[2] += 8;
						break;
					default:
						...
				}
				
static inline bool ip_rcv_options(struct sk_buff *skb) {
				...
				if (unlikely(opt->srr)) {
					struct in_device *in_dev = __in_dev_get_rcu(dev);
					if (in_dev) {
						if (!IN_DEV_SOURCE_ROUTE(in_dev)) {
							. . .
							goto drop;
						}
					}
					if (ip_options_rcv_srr(skb))
						goto drop;
				...						
				}
				
void ip_options_fragment(struct sk_buff *skb)
{
	unsigned char *optptr = skb_network_header(skb) + sizeof(struct iphdr);
	struct ip_options *opt = &(IPCB(skb)->opt);
	int l = opt->optlen;
	int optlen;	
	while (l > 0) {
		switch (*optptr) {
		case IPOPT_END:
			return;
		case IPOPT_NOOP:
			l--;
			optptr++;
			continue;
		}
		optlen = optptr[1];
		if (optlen<2 || optlen>l)
			return;	
		if (!IPOPT_COPIED(*optptr))
			memset(optptr, IPOPT_NOOP, optlen);
			l -= optlen;
			optptr += optlen; 
		}		
	opt->ts = 0;
	opt->rr = 0;
	opt->rr_needaddr = 0;
	opt->ts_needaddr = 0;
	opt->ts_needtime = 0;
}
(net/ipv4/ip_options.c)

void ip_options_build(struct sk_buff *skb, struct ip_options *opt,
			_be32 daddr, struct rtable *rt, int is_frag)
{
	unsigned char *iph = skb_network_header(skb);
	memcpy(&(IPCB(skb)->opt), opt, sizeof(struct ip_options));
	memcpy(iph+sizeof(struct iphdr), opt->__data, opt->optlen);
	opt = &(IPCB(skb)->opt);
	if (opt->srr)
		memcpy(iph+opt->srr+iph[opt->srr+1]-4, &daddr, 4);
	if (!is_frag) {
		if (opt->rr_needaddr)
			ip_rt_get_source(iph+opt->rr+iph[opt->rr+2]-5, skb, rt);
		if (opt->ts_needaddr)
			ip_rt_get_source(iph+opt->ts+iph[opt->ts+2]-9, skb, rt);
		if (opt->ts_needtime) {
			struct timespec tv;
			_be32 midtime;
			getnstimeofday(&tv);
			midtime = htonl((tv.tv_sec % 86400) *
				MSEC_PER_SEC + tv.tv_nsec / NSEC_PER_MSEC);
			memcpy(iph+opt->ts+iph[opt->ts+2]-5, &midtime, 4);
		}
		return;
	}
	if (opt->rr) {
		memset(iph+opt->rr, IPOPT_NOP, iph[opt->rr+1]);
		opt->rr = 0;
		opt->rr_needaddr = 0;
	}
	if (opt->ts) {
		memset(iph+opt->ts, IPOPT_NOP, iph[opt->ts+1]);
		opt->ts = 0;
		opt->ts_needaddr = opt->ts_needtime = 0;
	}
}

static int raw_send_hdrinc(struct sock *sk, struct flowi4 *fl4, void *from, size_t length,
                           struct rtable **rtp, unsigned int flags)
{
	...
	err = NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, NULL,
		rt->dst.dev, dst_output);
	...
}
		
int ip_queue_xmit(struct sk_buff *skb, struct flowi *fl)
{
	. . .
	/* Make sure we can route this packet. */
	rt = (struct rtable *)__sk_dst_check(sk, 0);	
	
	if (rt == NULL) {
		_be32 daddr;
		/* Use correct destination address if we have options. */
		daddr = inet->inet_daddr;
		if (inet_opt && inet_opt->opt.srr)
			daddr = inet_opt->opt.faddr;	
		/* If this fails, retransmit mechanism of transport layer will
		* keep trying until route appears or the connection times
		* itself out.
		*/
		rt = ip_route_output_ports(sock_net(sk), fl4, sk,
			daddr, inet->inet_saddr,
			inet->inet_dport,
			inet->inet_sport,
			sk->sk_protocol,
			RT_CONN_FLAGS(sk),
			sk->sk_bound_dev_if);
		if (IS_ERR(rt))
			goto no_route;
		sk_setup_caps(sk, &rt->dst);
	}
	skb_dst_set_noref(skb, &rt->dst);
	. . .		
	if (inet_opt && inet_opt->opt.is_strictroute && rt->rt_uses_gateway)
		goto no_route;
	/* OK, we know where to send it, allocate and build IP header. */
	skb_push(skb, sizeof(struct iphdr) + (inet_opt ? inet_opt->opt.optlen : 0));
	
	skb_reset_network_header(skb);
	iph = ip_hdr(skb);
	*((__be16 *)iph) = htons((4 << 12) | (5 << 8) | (inet->tos & 0xff));
	if (ip_dont_fragment(sk, &rt->dst) && !skb->local_df)
		iph->frag_off = htons(IP_DF);
	else
		iph->frag_off = 0;
	iph->ttl = ip_select_ttl(inet, &rt->dst);
	iph->protocol = sk->sk_protocol;
	ip_copy_addrs(iph, fl4);

	if (inet_opt && inet_opt->opt.optlen) {
		iph->ihl += inet_opt->opt.optlen >> 2;
		ip_options_build(skb, &inet_opt->opt, inet->inet_daddr, rt, 0);
	}
	
	ip_select_ident_more(iph, &rt->dst, sk,
		(skb_shinfo(skb)->gso_segs ?: 1) - 1);
	skb->priority = sk->sk_priority;
	skb->mark = sk->sk_mark;
	
	res = ip_local_out(skb);
	
int ip_append_data(struct sock *sk, struct flowi4 *fl4,
		   int getfrag(void *from, char *to, int offset, int len,
		   	       int odd, struct sk_buff *skb),
		   void *from, int length, int transhdrlen,
		   struct ipcm_cookie *ipc, struct rtable **rtp,
		   unsigned int flags)
{
	struct inet_sock *inet = inet_sk(sk);
	int err;
	if (flags&MSG_PROBE)
		return 0;
	if (skb_queue_empty(&sk->sk_write_queue)) {
		err = ip_setup_cork(sk, &inet->cork.base, ipc, rtp);
		if (err)
			return err;
	} else {
		transhdrlen = 0;
	}
	return __ip_append_data(sk, fl4, &sk->sk_write_queue, &inet->cork.base,
				sk_page_frag(sk), getfrag,
				from, length, transhdrlen, flags);
}	
	
int ip_fragment(struct sk_buff *skb, int (*output)(struct sk_buff *))
{
	unsigned int mtu, hlen, left, len, ll_rs;
	. . .
	struct rtable *rt = skb_rtable(skb);
	int err = 0;
	dev = rt->dst.dev;
	. . .
	iph = ip_hdr(skb);
	if (unlikely(((iph->frag_off & htons(IP_DF)) && !skb->local_df) ||
		(IPCB(skb)->frag_max_size &&
		   IPCB(skb)->frag_max_size > dst_mtu(&rt->dst)))) {
		IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGFAILS);
		icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,
			  htonl(ip_skb_dst_mtu(skb)));
		kfree_skb(skb);
		return -EMSGSIZE;
	}
	. . .
	hlen = iph->ihl * 4;
	. . .
	if (skb_has_frag_list(skb)) {
		struct sk_buff *frag, *frag2;
		int first_len = skb_pagelen(skb);
		. . .
		err = 0;
		offset = 0;
		frag = skb_shinfo(skb)->frag_list;
		
		skb_frag_list_init(skb);
		skb->data_len = first_len - skb_headlen(skb);
		skb->len = first_len;
		iph->tot_len = htons(first_len);
		iph->frag_off = htons(IP_MF);

		ip_send_check(iph);

		for (;;) {
			/* Prepare header of the next frame,
			* before previous one went down. */
			if (frag) {
				frag->ip_summed = CHECKSUM_NONE;
				skb_reset_transport_header(frag);
				_skb_push(frag, hlen);
				skb_reset_network_header(frag);	
				memcpy(skb_network_header(frag), iph, hlen);
				iph = ip_hdr(frag);
				iph->tot_len = htons(frag->len);
				ip_copy_metadata(frag, skb);
				if (offset == 0)
					ip_options_fragment(frag);
				offset += skb->len - hlen;
				iph->frag_off = htons(offset>>3);
				if (frag->next != NULL)
					iph->frag_off |= htons(IP_MF);
				/* Ready, complete checksum */
				ip_send_check(iph);
			}
			err = output(skb);
			if (!err)
				IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGCREATES);
			if (err || !frag)
				break;
			skb = frag;
			frag = skb->next;
			skb->next = NULL;
		}
		if (err == 0) {
			IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGOKS);
			return 0;
		}
		while (frag) {
			skb = frag->next;
			kfree_skb(frag);
			frag = skb;
		}
		IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGFAILS);
		return err;
		
	. . .
	iph = ip_hdr(skb);
		left = skb->len - hlen; /* Space per frame */
		. . .
		while (left > 0) {
			len = left;
			/* IF: it doesn't fit, use 'mtu' - the data space left */
			if (len > mtu)
				len = mtu;	
			if (len < left) {
				len &= ~7;
			}
			if ((skb2 = alloc_skb(len+hlen+ll_rs, GFP_ATOMIC)) == NULL) {
				NETDEBUG(KERN_INFO "IP: frag: no memory for new fragment!\n");
				err = -ENOMEM;
				goto fail;
			}
			/*
			* Set up data on packet
			*/	
			ip_copy_metadata(skb2, skb);
			skb_reserve(skb2, ll_rs);
			skb_put(skb2, len + hlen);
			skb_reset_network_header(skb2);
			skb2->transport_header = skb2->network_header + hlen;
			/*
			* Charge the memory for the fragment to any owner
			* it might possess
			*/
			if (skb->sk)
				skb_set_owner_w(skb2, skb->sk);
			/*
			* Copy the packet header into the new buffer.
			*/
			skb_copy_from_linear_data(skb, skb_network_header(skb2), hlen);
			/*
			* Copy a block of the IP datagram.
			*/
			if (skb_copy_bits(skb, ptr, skb_transport_header(skb2), len))
				BUG();
			left -= len;
			/*
			* Fill in the new header fields.
			*/
			iph = ip_hdr(skb2);	
			iph->frag_off = htons((offset >> 3));
			. . .
			if (offset == 0)
				ip_options_fragment(skb);
			if (left > 0 || not_last_frag)
				iph->frag_off |= htons(IP_MF);
			ptr += len;
			offset += len;
			/*
			* Put this fragment into the sending queue.
			*/
			iph->tot_len = htons(len + hlen);	
			ip_send_check(iph);
			err = output(skb2);
			if (err)
				goto fail;
			IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGCREATES);
		}
		consume_skb(skb);
		IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGOKS);
		return err;		

int ip_local_deliver(struct sk_buff *skb)
{
	/*
	* Reassemble IP fragments.
	*/
	if (ip_is_fragment(ip_hdr(skb))) {
		if (ip_defrag(skb, IP_DEFRAG_LOCAL_DELIVER))
			return 0;
	}
	return NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_IN, skb, skb->dev, NULL,
			ip_local_deliver_finish);
}
(net/ipv4/ip_input.c)

static inline bool ip_is_fragment(const struct iphdr *iph)
{
	return (iph->frag_off & htons(IP_MF | IP_OFFSET)) != 0;
}
(include/net/ip.h)

struct ipq {
	struct inet_frag_queue q;
	u32 user;
	_be32 saddr;
	_be32 daddr;
	_be16 id;
	u8 protocol;
	u8 ecn; /* RFC3168 support */
	int iif;
	unsigned int rid;
	struct inet_peer *peer;
};

int ip_defrag(struct sk_buff *skb, u32 user)
{
	struct ipq *qp;
	struct net *net;
	net = skb->dev ? dev_net(skb->dev) : dev_net(skb_dst(skb)->dev);
	IP_INC_STATS_BH(net, IPSTATS_MIB_REASMREQDS);
	/* Start by cleaning up the memory. */
	ip_evictor(net);
	/* Lookup (or create) queue header */
	if ((qp = ip_find(net, ip_hdr(skb), user)) != NULL) {
		int ret;
		spin_lock(&qp->q.lock);
		ret = ip_frag_queue(qp, skb);
		spin_unlock(&qp->q.lock);
		ipq_put(qp);
		return ret;
	}
	IP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);
	kfree_skb(skb);
	return -ENOMEM;
}

static int 	(struct ipq *qp, struct sk_buff *skb)
{
	struct sk_buff *prev, *next;
	. . .
	/* Determine the position of this fragment. */
	end = offset + skb->len - ihl;
	err = -EINVAL;
	/* Is this the final fragment? */
	if ((flags & IP_MF) == 0) {
		/* If we already have some bits beyond end
		* or have different end, the segment is corrupted.
		*/
		if (end < qp->q.len ||
			((qp->q.last_in & INET_FRAG_LAST_IN) && end != qp->q.len))
		goto err;
		qp->q.last_in |= INET_FRAG_LAST_IN;
		qp->q.len = end;
	} else {
		. . .
	}
	. . .
	prev = NULL;
	for (next = qp->q.fragments; next != NULL; next = next->next) {
		if (FRAG_CB(next)->offset >= offset)
			break; /* bingo! */
		prev = next;
	}
	FRAG_CB(skb)->offset = offset;
	/* Insert this fragment in the chain of fragments. */
	skb->next = next;
	if (!next)
		qp->q.fragments_tail = skb;
	if (prev)
		prev->next = skb;
	else
		qp->q.fragments = skb;
	. . .
	qp->q.meat += skb->len;	
	if (qp->q.last_in == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&
		qp->q.meat == qp->q.len) {
		unsigned long orefdst = skb->_skb_refdst;
		skb->_skb_refdst = 0UL;
		err = ip_frag_reasm(qp, prev, dev);
		skb->_skb_refdst = orefdst;
		return err;
	}

static int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev, struct net_device *dev)
{
	struct net *net = container_of(qp->q.net, struct net, ipv4.frags);
	struct iphdr *iph;
	struct sk_buff *fp, *head = qp->q.fragments;
	int len;
	...
	/* Allocate a new buffer for the datagram. */
	ihlen = ip_hdrlen(head);
	len = ihlen + qp->q.len;
	err = -E2BIG;
	if (len > 65535)
		goto out_oversize;
	...
	skb_push(head, head->data - skb_network_header(head));
	
int ip_forward(struct sk_buff *skb)
{
	struct iphdr *iph; /* Our header */
	struct rtable *rt; /* Route we use */
	struct ip_options *opt = &(IPCB(skb)->opt);
	
	if (skb_warn_if_lro(skb))
		goto drop;

	if (IPCB(skb)->opt.router_alert && ip_call_ra_chain(skb))
		return NET_RX_SUCCESS;
	if (skb->pkt_type != PACKET_HOST)
		goto drop;
	if (ip_hdr(skb)->ttl <= 1)
		goto too_many_hops;. . .
	. . .	

	rt = skb_rtable(skb);
	if (opt->is_strictroute && rt->rt_uses_gateway)
		goto sr_failed;
	
	if (unlikely(skb->len > dst_mtu(&rt->dst) &&
		!skb_is_gso(skb) && (ip_hdr(skb)->frag_off & htons(IP_DF)))
		&& !skb->local_df) {
		IP_INC_STATS(dev_net(rt->dst.dev), IPSTATS_MIB_FRAGFAILS);
		icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,
			htonl(dst_mtu(&rt->dst)));
		goto drop; 
	}

	/* We are about to mangle packet. Copy it! */
	if (skb_cow(skb, LL_RESERVED_SPACE(rt->dst.dev)+rt->dst.header_len))
		goto drop;
	iph = ip_hdr(skb);
	
	/* Decrease ttl after skb cow done */
	ip_decrease_ttl(iph);	
	/*
	* We now generate an ICMP HOST REDIRECT giving the route
	* we calculated.
	*/
	if (rt->rt_flags&RTCF_DOREDIRECT && !opt->srr && !skb_sec_path(skb))
		ip_rt_send_redirect(skb);
	skb->priority = rt_tos2priority(iph->tos);
	return NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, skb, skb->dev,
		rt->dst.dev, ip_forward_finish);	
	
	. . .
sr_failed:
	icmp_send(skb, ICMP_DEST_UNREACH, ICMP_SR_FAILED, 0);
	goto drop;
. . .	
too_many_hops:
	/* Tell the sender its packet died... */
	IP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_INHDRERRORS);
	icmp_send(skb, ICMP_TIME_EXCEEDED, ICMP_EXC_TTL, 0);
. . .
drop:
        kfree_skb(skb);
        return NET_RX_DROP;
 }

static int ip_forward_finish(struct sk_buff *skb)
{
	struct ip_options *opt = &(IPCB(skb)->opt);
	IP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTFORWDATAGRAMS);
	IP_ADD_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTOCTETS, skb->len);
	if (unlikely(opt->optlen))
		ip_forward_options(skb);
	return dst_output(skb);
}




	

	
