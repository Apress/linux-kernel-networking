chapter 11
-----------

struct socket {
	socket_state state;
	kmemcheck_bitfield_begin(type);
	short type;
	kmemcheck_bitfield_end(type);
	unsigned long flags;
	. . .
	struct file *file;
	struct sock *sk;
	const struct proto_ops *ops;
};
(include/linux/net.h)

struct sock {
	struct sk_buff_head sk_receive_queue;
	int sk_rcvbuf;
	unsigned long sk_flags;
	int sk_sndbuf;
	struct sk_buff_head sk_write_queue;
	. . .
	unsigned int sk_shutdown : 2,
	sk_no_check : 2,
	sk_protocol : 8,
	sk_type : 16;
	. . .
	void (*sk_data_ready)(struct sock *sk, int bytes);
	void (*sk_write_space)(struct sock *sk);
};
(include/net/sock.h)

SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)
{
	int retval;
	struct socket *sock;
	int flags;
	. . .
	retval = sock_create(family, type, protocol, &sock);
	if (retval < 0)
		goto out;
	. . .
	retval = sock_map_fd(sock, flags & (O_CLOEXEC | O_NONBLOCK));
	if (retval < 0)
		goto out_release;
out:
	. . .
	return retval;
}
(net/socket.c)

struct msghdr {
	void *msg_name; /* Socket name */
	int msg_namelen; /* Length of name */
	struct iovec *msg_iov; /* Data blocks */
	_kernel_size_t msg_iovlen; /* Number of blocks */
	void *msg_control; /* Per protocol magic (eg BSD file descriptor passing) */
	_kernel_size_t msg_controllen; /* Length of cmsg list */
	unsigned int msg_flags;
};

(include/linux/socket.h)

struct udphdr {
	_be16 source;
	_be16 dest;
	_be16 len;
	_sum16 check;
};
(include/uapi/linux/udp.h)

const struct net_protocol udp_protocol = {
	.handler = udp_rcv,
	.err_handler = udp_err,
	.no_policy = 1,
	.netns_ok = 1,
};
(net/ipv4/af_inet.c)

static int __init inet_init(void)
{
	. . .
	if (inet_add_protocol(&udp_protocol, IPPROTO_UDP) < 0)
		pr_crit("%s: Cannot add UDP protocol\n", __func__);
	. . .
}
(net/ipv4/af_inet.c)

struct proto udp_prot = {
	.name = "UDP",
	.owner = THIS_MODULE,
	.close = udp_lib_close,
	.connect = ip4_datagram_connect,
	.disconnect = udp_disconnect,
	.ioctl = udp_ioctl,
	. . .
	.setsockopt = udp_setsockopt,
	.getsockopt = udp_getsockopt,
	.sendmsg = udp_sendmsg,
	.recvmsg = udp_recvmsg,
	.sendpage = udp_sendpage,
	. . .
};
(net/ipv4/udp.c)


int __init inet_init(void)
{
	int rc = -EINVAL;
	. . .
	rc = proto_register(&udp_prot, 1);
	. . .
}
(net/ipv4/af_inet.c)


struct ipcm_cookie {
	_be32 addr;
	int oif;
	struct ip_options_rcu *opt;
	_u8 tx_flags;
	};
(include/net/ip.h)

int udp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
		size_t len)
{
	int corkreq = up->corkflag || msg->msg_flags&MSG_MORE;
	struct inet_sock *inet = inet_sk(sk);
	
	if (len > 0xFFFF)
		return -EMSGSIZE;
	
	if (msg->msg_name) {
		struct sockaddr_in *usin = (struct sockaddr_in *)msg->msg_name;
		if (msg->msg_namelen < sizeof(*usin))
			return -EINVAL;
		if (usin->sin_family != AF_INET) {
			if (usin->sin_family != AF_UNSPEC)
				return -EAFNOSUPPORT;
		}
		daddr = usin->sin_addr.s_addr;
		dport = usin->sin_port;
		if (dport == 0)
			return -EINVAL;
	} else {
		if (sk->sk_state != TCP_ESTABLISHED)
			return -EDESTADDRREQ;	
		daddr = inet->inet_daddr;
		dport = inet->inet_dport;
		/* Open fast path for connected socket.
		Route will not be used, if at least one option is set.
		*/
		connected = 1;
	}
	. . .
	
	if (msg->msg_controllen) {
		err = ip_cmsg_send(sock_net(sk), msg, &ipc);
		if (err)
			return err;
		if (ipc.opt)
			free = 1;
		connected = 0;
	}
	. . .
	if (connected)
		rt = (struct rtable *)sk_dst_check(sk, 0);
. . .
	if (rt == NULL) {
		struct net *net = sock_net(sk);
		fl4 = &fl4_stack;
		flowi4_init_output(fl4, ipc.oif, sk->sk_mark, tos,
			RT_SCOPE_UNIVERSE, sk->sk_protocol,
			inet_sk_flowi_flags(sk)|FLOWI_FLAG_CAN_SLEEP,
			faddr, saddr, dport, inet->inet_sport);
		security_sk_classify_flow(sk, flowi4_to_flowi(fl4));
		rt = ip_route_output_flow(net, fl4, sk);
		if (IS_ERR(rt)) {
			err = PTR_ERR(rt);
			rt = NULL;
			if (err == -ENETUNREACH)
				IP_INC_STATS_BH(net, IPSTATS_MIB_OUTNOROUTES);
			goto out;
		}
. . .
	/* Lockless fast path for the non-corking case. */
	if (!corkreq) {
		skb = ip_make_skb(sk, fl4, getfrag, msg->msg_iov, ulen,
			sizeof(struct udphdr), &ipc, &rt,
			msg->msg_flags);
		err = PTR_ERR(skb);
		if (!IS_ERR_OR_NULL(skb))
			err = udp_send_skb(skb, fl4);
		goto out;
	}
	lock_sock(sk);
do_append_data:
	up->len += ulen;

	err = ip_append_data(sk, fl4, getfrag, msg->msg_iov, ulen,
				sizeof(struct udphdr), &ipc, &rt,
				corkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags);
	
	if (err)
		udp_flush_pending_frames(sk);
	else if (!corkreq)
		err = udp_push_pending_frames(sk);
	else if (unlikely(skb_queue_empty(&sk->sk_write_queue)))
		up->pending = 0;
	release_sock(sk);
	
	
int udp_rcv(struct sk_buff *skb)
	{
		return __udp4_lib_rcv(skb, &udp_table, IPPROTO_UDP);
	}	
	
int __udp4_lib_rcv(struct sk_buff *skb, struct udp_table *udptable,
			int proto)
{
	struct sock *sk;
	struct udphdr *uh;
	unsigned short ulen;
	struct rtable *rt = skb_rtable(skb);
	_be32 saddr, daddr;
	struct net *net = dev_net(skb->dev);
	. . .
	uh = udp_hdr(skb);
	ulen = ntohs(uh->len);
	saddr = ip_hdr(skb)->saddr;
	daddr = ip_hdr(skb)->daddr;

	if (rt->rt_flags & (RTCF_BROADCAST|RTCF_MULTICAST))
		return __udp4_lib_mcast_deliver(net, skb, uh,
						saddr, daddr, udptable);	
	
	sk = __udp4_lib_lookup_skb(skb, uh->source, uh->dest, udptable);
	if (sk != NULL) {
		int ret = udp_queue_rcv_skb(sk, skb);
		sock_put(sk);
		/* a return value > 0 means to resubmit the input, but
		* it wants the return to be -protocol, or 0
		*/
		if (ret > 0)
			return -ret;
		return 0;
	}
	. . .	
	/* No socket. Drop packet silently, if checksum is wrong */
	if (udp_lib_checksum_complete(skb))
		goto csum_error;
	UDP_INC_STATS_BH(net, UDP_MIB_NOPORTS, proto == IPPROTO_UDPLITE);
	icmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, 0);
	/*
	* Hmm. We got an UDP packet to a port to which we
	* don't wanna listen. Ignore it.
	*/
	kfree_skb(skb);
	return 0;
}


struct tcphdr {
	_be16 source;
	_be16 dest;
	_be32 seq;
	_be32 ack_seq;
#if defined(__LITTLE_ENDIAN_BITFIELD)
	_u16 res1:4,
	doff:4,
	fin:1,
	syn:1,
	rst:1,
	psh:1,
	ack:1,
	urg:1,
	ece:1,
	cwr:1;
#elif defined(__BIG_ENDIAN_BITFIELD)
	_u16 doff:4,
	res1:4,
	cwr:1,
	ece:1,
	urg:1,
	ack:1,
	psh:1,
	rst:1,
	syn:1,
	fin:1;
#else
#error "Adjust your <asm/byteorder.h> defines"
#endif
	_be16 window;
	_sum16 check;
	_be16 urg_ptr;
};
(include/uapi/linux/tcp.h)

static const struct net_protocol tcp_protocol = {
	.early_demux = tcp_v4_early_demux,
	.handler = tcp_v4_rcv,
	.err_handler = tcp_v4_err,
	.no_policy = 1,
	.netns_ok = 1,
};
(net/ipv4/af_inet.c)

static int __init inet_init(void)
{
	. . .
	if (inet_add_protocol(&tcp_protocol, IPPROTO_TCP) < 0)
		pr_crit("%s: Cannot add TCP protocol\n", __func__);
	. . .
}
(net/ipv4/af_inet.c)

struct proto tcp_prot = {
	.name = "TCP",
	.owner = THIS_MODULE,
	.close = tcp_close,
	.connect = tcp_v4_connect,
	.disconnect = tcp_disconnect,
	.accept = inet_csk_accept,
	.ioctl = tcp_ioctl,
	.init = tcp_v4_init_sock,
	. . .
};
(net/ipv4/tcp_ipv4.c)

static int __init inet_init(void)
{
	int rc;
	. . .
	rc = proto_register(&tcp_prot, 1);
	. . .
}
(net/ipv4/af_inet.c)

int tcp_v4_rcv(struct sk_buff *skb)
{
	struct sock *sk;
	. . .
	sk = __inet_lookup_skb(&tcp_hashinfo, skb, th->source, th->dest);
	. . .
	if (!sk)
		goto no_tcp_socket;
	if (!sock_owned_by_user(sk)) {
		. . .
		{
		if (!tcp_prequeue(sk, skb))
			ret = tcp_v4_do_rcv(sk, skb);
		}
	} else if (unlikely(sk_add_backlog(sk, skb,
				sk->sk_rcvbuf + sk->sk_sndbuf))) {
		bh_unlock_sock(sk);
		NET_INC_STATS_BH(net, LINUX_MIB_TCPBACKLOGDROP);
		goto discard_and_relse;
	}
. . .

int tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
{
	if (sk->sk_state == TCP_ESTABLISHED) { /* Fast path */
		. . .
		if (tcp_rcv_established(sk, skb, tcp_hdr(skb), skb->len)) {
			rsk = sk;
			goto reset;
		}
		return 0;
	}
	. . .	
	if (sk->sk_state == TCP_LISTEN) {
		struct sock *nsk = tcp_v4_hnd_req(sk, skb);
		. . .
	}		
	
	if (tcp_rcv_state_process(sk, skb, tcp_hdr(skb), skb->len)) {
		rsk = sk;
		goto reset;
	}
	return 0;
reset:
	tcp_v4_send_reset(rsk, skb);
	. . .
}		

int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
		size_t size)
{
	struct iovec *iov;
	struct tcp_sock *tp = tcp_sk(sk);
	struct sk_buff *skb;
	int iovlen, flags, err, copied = 0;
	int mss_now = 0, size_goal, copied_syn = 0, offset = 0;
	bool sg;
	long timeo;
	. . .
	
static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
				gfp_t gfp_mask)
{	
	. . .
	err = icsk->icsk_af_ops->queue_xmit(skb, &inet->cork.fl);
	. . .
}
(net/ipv4/tcp_output.c)


int sctp_init(void)
{
	int status = -EINVAL;
	. . .
	status = sctp_v4_add_protocol();
	if (status)
		goto err_add_protocol;
	/* Register SCTP with inet6 layer. */
	status = sctp_v6_add_protocol();
	if (status)
		goto err_v6_add_protocol;
	. . .
}
(net/sctp/protocol.c)

static const struct net_protocol sctp_protocol = {
	.handler = sctp_rcv,
	.err_handler = sctp_v4_err,
	.no_policy = 1,
};
(net/sctp/protocol.c)

static int sctp_v4_add_protocol(void)
{
	/* Register notifier for inet address additions/deletions. */
	register_inetaddr_notifier(&sctp_inetaddr_notifier);
	/* Register SCTP with inet layer. */
	if (inet_add_protocol(&sctp_protocol, IPPROTO_SCTP) < 0)
		return -EAGAIN;
	return 0;
}
(net/sctp/protocol.c)

typedef struct sctphdr {
	_be16 source;
	_be16 dest;
	_be32 vtag;
	_le32 checksum;
} __attribute__((packed)) sctp_sctphdr_t;
(include/linux/sctp.h)

typedef struct sctp_chunkhdr {
	_u8 type;
	_u8 flags;
	_be16 length;
} __packed sctp_chunkhdr_t;
(include/linux/sctp.h)

struct sctp_chunk {
	. . .
	atomic_t refcnt;
	union {
		_u8 *v;
		struct sctp_datahdr *data_hdr;
		struct sctp_inithdr *init_hdr;
		struct sctp_sackhdr *sack_hdr;
		struct sctp_heartbeathdr *hb_hdr;
		struct sctp_sender_hb_info *hbs_hdr;
		struct sctp_shutdownhdr *shutdown_hdr;
		struct sctp_signed_cookie *cookie_hdr;
		struct sctp_ecnehdr *ecne_hdr;
		struct sctp_cwrhdr *ecn_cwr_hdr;
		struct sctp_errhdr *err_hdr;
		struct sctp_addiphdr *addip_hdr;
		struct sctp_fwdtsn_hdr *fwdtsn_hdr;
		struct sctp_authhdr *auth_hdr;
	} subh;
	struct sctp_chunkhdr *chunk_hdr;
	struct sctphdr *sctp_hdr;
	struct sctp_association *asoc;
	/* What endpoint received this chunk? */
	struct sctp_ep_common *rcvr;
	. . .
	/* What is the origin IP address for this chunk? */
	union sctp_addr source;
	/* Destination address for this chunk. */
	union sctp_addr dest;
	. . .

	/* For an inbound chunk, this tells us where it came from.
	* For an outbound chunk, it tells us where we'd like it to
	* go. It is NULL if we have no preference.
	*/
	struct sctp_transport *transport;
	};
(include/net/sctp/structs.h)

struct sctp_association {
	...
	sctp_assoc_t assoc_id;
	/* These are those association elements needed in the cookie. */
	struct sctp_cookie c;
	/* This is all information about our peer. */
	struct {
		struct list_head transport_addr_list;
		
		. . .
		_u16 transport_count;
		_u16 port;
		. . .
		struct sctp_transport *primary_path;
		struct sctp_transport *active_path;
	} peer;
	sctp_state_t state;
	. . .
	struct sctp_priv_assoc_stats stats;
};
(include/net/sctp/structs.h).


struct dccp_hdr {
	_be16 dccph_sport,
	dccph_dport;
	_u8 dccph_doff;
#if defined(__LITTLE_ENDIAN_BITFIELD)
	_u8 dccph_cscov:4,
	dccph_ccval:4;
#elif defined(__BIG_ENDIAN_BITFIELD)
	_u8 dccph_ccval:4,
	dccph_cscov:4;
#else
#error "Adjust your <asm/byteorder.h> defines"
#endif
	_sum16 dccph_checksum;
#if defined(__LITTLE_ENDIAN_BITFIELD)
	_u8 dccph_x:1,
	dccph_type:4,
	dccph_reserved:3;
#elif defined(__BIG_ENDIAN_BITFIELD)
	_u8 dccph_reserved:3,
	dccph_type:4,
	dccph_x:1;
#else
#error "Adjust your <asm/byteorder.h> defines"
#endif
	_u8 dccph_seq2;
	_be16 dccph_seq;
};
(include/uapi/linux/dccp.h)

static struct proto dccp_v4_prot = {
	.name = "DCCP",
	.owner = THIS_MODULE,
	.close = dccp_close,
	.connect = dccp_v4_connect,
	.disconnect = dccp_disconnect,
	.ioctl = dccp_ioctl,
	.init = dccp_v4_init_sock,
	. . .
	.sendmsg = dccp_sendmsg,
	.recvmsg = dccp_recvmsg,
	. . .
}
(net/dccp/ipv4.c)

static const struct net_protocol dccp_v4_protocol = {
	.handler = dccp_v4_rcv,
	.err_handler = dccp_v4_err,
	.no_policy = 1,
	.netns_ok = 1,
};
(net/dccp/ipv4.c)

static int __init dccp_v4_init(void)
{
	int err = proto_register(&dccp_v4_prot, 1);
	if (err != 0)
		goto out;
	err = inet_add_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
	if (err != 0)
		goto out_proto_unregister;
	. . .
}
(net/dccp/ipv4.c)

static int dccp_v4_init_sock(struct sock *sk)
{
	static __u8 dccp_v4_ctl_sock_initialized;
	int err = dccp_init_sock(sk, dccp_v4_ctl_sock_initialized);
	if (err == 0) {
		if (unlikely(!dccp_v4_ctl_sock_initialized))
			dccp_v4_ctl_sock_initialized = 1;
		inet_csk(sk)->icsk_af_ops = &dccp_ipv4_af_ops;
	}
	return err;
}
(net/dccp/ipv4.c)

static int dccp_v4_rcv(struct sk_buff *skb)
{
	const struct dccp_hdr *dh;
	const struct iphdr *iph;
	struct sock *sk;
	int min_cov;
	
	if (dccp_invalid_packet(skb))
		goto discard_it;	
	sk = __inet_lookup_skb(&dccp_hashinfo, skb,
		dh->dccph_sport, dh->dccph_dport);
	
	if (sk == NULL) {
		. . .
		goto no_dccp_socket;
	}
	. . .
	return sk_receive_skb(sk, skb, 1);
	}
(net/dccp/ipv4.c)


int dccp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
		size_t len)
{
	const struct dccp_sock *dp = dccp_sk(sk);
	const int flags = msg->msg_flags;
	const int noblock = flags & MSG_DONTWAIT;
	struct sk_buff *skb;
	int rc, size;
	long timeo;
	
	skb = sock_alloc_send_skb(sk, size, noblock, &rc);
	lock_sock(sk);
	if (skb == NULL)
		goto out_release;
	skb_reserve(skb, sk->sk_prot->max_header);

	rc = memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len);
	if (rc != 0)
		goto out_discard;
	if (!timer_pending(&dp->dccps_xmit_timer))
		dccp_write_xmit(sk);	
	. . .
}
